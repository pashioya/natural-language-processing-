{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.58k/1.58k [00:00<00:00, 1.58MB/s]\n",
      "s:\\Development\\kdg\\Data\\5\\natural-language-processing\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\johna\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors: 100%|██████████| 1.63G/1.63G [01:32<00:00, 17.5MB/s]\n",
      "All PyTorch model weights were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 21.9MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 28.5MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 3.71MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "# Load summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_validity(word):\n",
    "    if word.is_alpha and word.text.lower() not in nlp.Defaults.stop_words:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def extract_sample_from_file(file_name, character_count, start_position=0):\n",
    "    possible_encodings = ['utf-8', 'latin-1', 'windows-1252']\n",
    "    unprocessed_text = ''\n",
    "    for encoding in possible_encodings:\n",
    "        try:\n",
    "            with open(file_name, 'r', encoding=encoding) as f:\n",
    "                f.seek(start_position)\n",
    "                text = f.read(character_count)\n",
    "                unprocessed_text += text\n",
    "            doc = nlp(text)\n",
    "            # Check and remove the first token if it's not a valid word\n",
    "            if check_word_validity(doc[0]):\n",
    "                print(\"removing first token: \", doc[0])\n",
    "                doc = doc[1:]\n",
    "\n",
    "            # Check and remove the last token if it's not a valid word\n",
    "            if check_word_validity(doc[-1]):\n",
    "                print(\"removing last token: \", doc[-1])\n",
    "                doc = doc[:-1]\n",
    "            return doc, unprocessed_text\n",
    "        except UnicodeDecodeError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "the_lindsays_sample, unprocessed_the_lindsays_sample  = extract_sample_from_file(os.path.join(\"data\",\"the_lindsays.txt\"), character_count=2000, start_position=10000)\n",
    "\n",
    "# Generate summary\n",
    "summary = summarizer(unprocessed_the_lindsays_sample, max_length=100, min_length=30, do_sample=False)[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: \n",
      " he railway\n",
      "station, I noticed a stout dog-cart standing at the corner of a\n",
      "by-road, under a tall, straggling thorn hedge. The youth who was seated\n",
      "in it made a sign to the coachman to stop, and I was made aware that\n",
      "the dog-cart had been sent for me. I got down, and as I bade good-night\n",
      "to the cross-questioning farmer, I observed a grim smile of triumph on\n",
      "his firmly compressed lips. He evidently knew the dog-cart, and would\n",
      "now be able to trace the mysterious stranger.\n",
      "\n",
      "I and my portmanteau were finally left on the side of the road, and\n",
      "the young man in the dog-cart civilly turned the vehicle round (with\n",
      "some difficulty on account of the narrow road), and drew up beside me,\n",
      "to save my carrying my luggage a dozen yards. At first I was a little\n",
      "uncertain whether I had one of my third (or fourth, which is it?)\n",
      "cousins before me, or simply a young man from Mr. Lindsay’s farm. He\n",
      "was dressed in very coarse tweeds, and his hands were rough, and spoke\n",
      "of manual labour, and he breathed the incense of the farm-yard; but I\n",
      "thought his finely-cut features and sensitive lips bespoke him to be of\n",
      "gentle blood, and, luckily, I made a hit in the right direction.\n",
      "\n",
      "‘You are one of Mr. Lindsay’s sons, I think--that is to say, one of my\n",
      "cousins,’ I said, as I shook hands with him.\n",
      "\n",
      "The youth’s face lighted up with a blush and a pleasant smile as he\n",
      "answered that he was, and held open the apron of the dog-cart for me to\n",
      "get in. In another moment we were off, the sturdy old mare between the\n",
      "shafts carrying us along at a very fair pace.\n",
      "\n",
      "There are some people, Sophy, who wear their characters written on\n",
      "their faces, and Alec Lindsay is one of them. I could see, even as\n",
      "we drove together along that solitary lane in the autumn twilight,\n",
      "that his was a frank, ingenuous nature, shy, sensitive, and reserved.\n",
      "I mean that his shyness made him reserved, but his thoughts and\n",
      "feelings showed themselves in his face without his knowing it, so\n",
      "little idea had he of purposely concealing himself. Such\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Text: \\n\", unprocessed_the_lindsays_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "Alec Lindsay is one of those people who wear their characters written on their faces. I could see, even as we drove together along that solitary lane in the autumn twilight, that his was a frank, ingenuous nature, shy, sensitive, and reserved. I mean that his shyness made him reserved, but his thoughts and feelings showed themselves in his face.\n"
     ]
    }
   ],
   "source": [
    "# Concatenate key sentences into a single string for summarization\n",
    "input_text = \" \".join(key_sentences)\n",
    "\n",
    "# Use the pre-trained LLM for summarization\n",
    "summary = summarizer(input_text, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "print(\"Generated Summary:\")\n",
    "print(summary[0][\"summary_text\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
