{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "# Load summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_word_validity(word):\n",
    "    if word.is_alpha and word.text.lower() not in nlp.Defaults.stop_words:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def extract_sample_from_file(file_name, character_count, start_position=0):\n",
    "    possible_encodings = ['utf-8', 'latin-1', 'windows-1252']\n",
    "    unprocessed_text = ''\n",
    "    for encoding in possible_encodings:\n",
    "        try:\n",
    "            with open(file_name, 'r', encoding=encoding) as f:\n",
    "                f.seek(start_position)\n",
    "                text = f.read(character_count)\n",
    "                unprocessed_text += text\n",
    "            doc = nlp(text)\n",
    "            # Check and remove the first token if it's not a valid word\n",
    "            if check_word_validity(doc[0]):\n",
    "                print(\"removing first token: \", doc[0])\n",
    "                doc = doc[1:]\n",
    "\n",
    "            # Check and remove the last token if it's not a valid word\n",
    "            if check_word_validity(doc[-1]):\n",
    "                print(\"removing last token: \", doc[-1])\n",
    "                doc = doc[:-1]\n",
    "            return doc, unprocessed_text\n",
    "        except UnicodeDecodeError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing first token:  n\n",
      "removing last token:  ho\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "the_lindsays_sample, unprocessed_the_lindsays_sample  = extract_sample_from_file(os.path.join(\"data\",\"the_lindsays.txt\"), character_count=2000, start_position=10000)\n",
    "\n",
    "# Generate summary\n",
    "# summary = summarizer(unprocessed_the_lindsays_sample, max_length=100, min_length=30, do_sample=False)[0]\n",
    "\n",
    "summary = summarizer(unprocessed_the_lindsays_sample, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: \n",
      " n, and as I bade good-night\n",
      "to the cross-questioning farmer, I observed a grim smile of triumph on\n",
      "his firmly compressed lips. He evidently knew the dog-cart, and would\n",
      "now be able to trace the mysterious stranger.\n",
      "\n",
      "I and my portmanteau were finally left on the side of the road, and\n",
      "the young man in the dog-cart civilly turned the vehicle round (with\n",
      "some difficulty on account of the narrow road), and drew up beside me,\n",
      "to save my carrying my luggage a dozen yards. At first I was a little\n",
      "uncertain whether I had one of my third (or fourth, which is it?)\n",
      "cousins before me, or simply a young man from Mr. Lindsay’s farm. He\n",
      "was dressed in very coarse tweeds, and his hands were rough, and spoke\n",
      "of manual labour, and he breathed the incense of the farm-yard; but I\n",
      "thought his finely-cut features and sensitive lips bespoke him to be of\n",
      "gentle blood, and, luckily, I made a hit in the right direction.\n",
      "\n",
      "‘You are one of Mr. Lindsay’s sons, I think--that is to say, one of my\n",
      "cousins,’ I said, as I shook hands with him.\n",
      "\n",
      "The youth’s face lighted up with a blush and a pleasant smile as he\n",
      "answered that he was, and held open the apron of the dog-cart for me to\n",
      "get in. In another moment we were off, the sturdy old mare between the\n",
      "shafts carrying us along at a very fair pace.\n",
      "\n",
      "There are some people, Sophy, who wear their characters written on\n",
      "their faces, and Alec Lindsay is one of them. I could see, even as\n",
      "we drove together along that solitary lane in the autumn twilight,\n",
      "that his was a frank, ingenuous nature, shy, sensitive, and reserved.\n",
      "I mean that his shyness made him reserved, but his thoughts and\n",
      "feelings showed themselves in his face without his knowing it, so\n",
      "little idea had he of purposely concealing himself. Such a face is\n",
      "always interesting; and besides, there was an under-expression of\n",
      "dissatisfaction, of unrest, I hardly know what to call it, in his eyes,\n",
      "which was scarcely natural in so young a lad. He could not be more than\n",
      "eighteen or nineteen.\n",
      "\n",
      "After half an ho\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Text: \\n\", unprocessed_the_lindsays_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "The young man in the dog-cart civilly turned the vehicle round (with some difficulty on account of the narrow road), and drew up beside me. At first I was a littleuncertain whether I had one of my third (or fourth, which is it?) grotesquecousins before me, or simply a young man from Mr. Lindsay’s farm. But I could see, even as we drove together along that solitary lane, that his was a frank, ingenuous nature.\n"
     ]
    }
   ],
   "source": [
    "# # Turn key sentences into a single string for summarization\n",
    "# key_sentences = [sentence.text for sentence in doc.sents if len(sentence.text.split()) > 5]\n",
    "# input_text = \" \".join(key_sentences)\n",
    "\n",
    "# # Use the pre-trained LLM for summarization\n",
    "# summary = summarizer(input_text, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "print(\"Generated Summary:\")\n",
    "print(summary[0][\"summary_text\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
